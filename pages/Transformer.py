import os
import pickle
from io import StringIO

import streamlit as st

from lightGE.core.transformer.transformer import Transformer, predict
from lightGE.compoment.controller import Controller
from lightGE.core.nn import *

MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB
check_eval = False
uploaded_file = None
global optimizer_adam
dataDir = ['res/simple_translation/simple_translation_en.txt', 'res/simple_translation/val_simple_translation_en.txt',
           'res/simple_translation/simple_translation_zh.txt', 'res/simple_translation/val_simple_translation_zh.txt']

# -- Set page config
pagetitle = 'nnengine-Transformer'

if 'hyper_param_dict' not in st.session_state:
    st.session_state.hyper_param_dict = dict()

if 'model_repr' not in st.session_state:
    st.session_state.model_repr = ''

if 'model_create_time' not in st.session_state:
    st.session_state.model_create_time = None

if 'model' not in st.session_state:
    st.session_state.model = None

if 'controller' not in st.session_state:
    st.session_state.controller = Controller()

# æ–‡ä»¶ä¸Šä¼ çŠ¶æ€å˜é‡
if 'transformer_training_src_uploaded' not in st.session_state:
    st.session_state.transformer_training_src_uploaded = False

if 'transformer_training_tgt_uploaded' not in st.session_state:
    st.session_state.transformer_training_tgt_uploaded = False

if 'transformer_eval_src_uploaded' not in st.session_state:
    st.session_state.transformer_eval_src_uploaded = False

if 'transformer_eval_tgt_uploaded' not in st.session_state:
    st.session_state.transformer_eval_tgt_uploaded = False

# æ–‡ä»¶è·¯å¾„è®°å½•å˜é‡
if 'transformer_training_src_path' not in st.session_state:
    st.session_state.transformer_training_src_path = ''

if 'transformer_training_tgt_path' not in st.session_state:
    st.session_state.transformer_training_tgt_path = ''

if 'transformer_eval_src_path' not in st.session_state:
    st.session_state.transformer_eval_src_path = ''

if 'transformer_eval_tgt_path' not in st.session_state:
    st.session_state.transformer_eval_tgt_path = ''

def training_src_uploaded():
    st.session_state.transformer_training_src_uploaded = True

def training_tgt_uploaded():
    st.session_state.transformer_training_tgt_uploaded = True

def eval_src_uploaded():
    st.session_state.transformer_eval_src_uploaded = True

def eval_tgt_uploaded():
    st.session_state.transformer_eval_tgt_uploaded = True

st.set_page_config(page_title=pagetitle, page_icon=":eyeglasses:")

with st.sidebar:
    st.subheader('å½“å‰è¶…å‚æ•°é…ç½®', divider='blue')
    with st.container(border=True):
        st.json(st.session_state.hyper_param_dict)

st.title("Transformer")
train_tab, prediction_tab = st.tabs(['æœºå™¨ç¿»è¯‘ä»»åŠ¡-æ¨¡å‹è®­ç»ƒ', 'æœºå™¨ç¿»è¯‘ä»»åŠ¡-æ¨¡å‹é¢„æµ‹'])

with train_tab:
    with st.container(border=True):
        st.write('**æœºå™¨ç¿»è¯‘æ•°æ®é›†é€‰æ‹©**')
        # training src
        uploaded_training_src_file = st.file_uploader('é€‰æ‹©è®­ç»ƒé›†-æºè¯­è¨€æ–‡æœ¬æ–‡ä»¶', type='.txt',
                                                      on_change=training_src_uploaded)
        if st.session_state.transformer_training_src_uploaded and uploaded_training_src_file is not None:
            with st.status('txtæ–‡ä»¶å¤„ç†ä¸­...'):
                st.write('è¯»å–txtæ–‡ä»¶ä¸­...')
                file_path = 'res/translation/training_src.txt'
                if os.path.exists(file_path):
                    os.remove(file_path)
                stringio = StringIO(uploaded_training_src_file.getvalue().decode("utf-8"))
                content = stringio.read()
                content = content.replace('\r\n', '\n')
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                st.session_state.transformer_training_src_path = file_path
                st.write('txtæ–‡ä»¶å¤„ç†å®Œæˆâœ…')
            st.session_state.transformer_training_src_uploaded = False

        # training tgt
        uploaded_training_tgt_file = st.file_uploader('é€‰æ‹©è®­ç»ƒé›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬æ–‡ä»¶', type='.txt',
                                                      on_change=training_tgt_uploaded)
        if st.session_state.transformer_training_tgt_uploaded and uploaded_training_tgt_file is not None:
            with st.status('txtæ–‡ä»¶å¤„ç†ä¸­...'):
                st.write('è¯»å–txtæ–‡ä»¶ä¸­...')
                file_path = 'res/translation/training_tgt.txt'
                if os.path.exists(file_path):
                    os.remove(file_path)
                stringio = StringIO(uploaded_training_tgt_file.getvalue().decode("utf-8"))
                content = stringio.read()
                content = content.replace('\r\n', '\n')
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                st.session_state.transformer_training_tgt_path = file_path
                st.write('txtæ–‡ä»¶å¤„ç†å®Œæˆâœ…')
            st.session_state.transformer_training_tgt_uploaded = False

        # eval src
        uploaded_eval_src_file = st.file_uploader('é€‰æ‹©æµ‹è¯•é›†-æºè¯­è¨€æ–‡æœ¬æ–‡ä»¶', type='.txt',
                                                      on_change=eval_src_uploaded)
        if st.session_state.transformer_eval_src_uploaded and uploaded_eval_src_file is not None:
            with st.status('txtæ–‡ä»¶å¤„ç†ä¸­...'):
                st.write('è¯»å–txtæ–‡ä»¶ä¸­...')
                file_path = 'res/translation/eval_src.txt'
                if os.path.exists(file_path):
                    os.remove(file_path)
                stringio = StringIO(uploaded_eval_src_file.getvalue().decode("utf-8"))
                content = stringio.read()
                content = content.replace('\r\n', '\n')
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                st.session_state.transformer_eval_src_path = file_path
                st.write('txtæ–‡ä»¶å¤„ç†å®Œæˆâœ…')
            st.session_state.classification_eval_set_uploaded = False

        # eval tgt
        uploaded_eval_tgt_file = st.file_uploader('é€‰æ‹©æµ‹è¯•é›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬æ–‡ä»¶', type='.txt',
                                                      on_change=eval_tgt_uploaded)
        if st.session_state.transformer_eval_tgt_uploaded and uploaded_eval_tgt_file is not None:
            with st.status('txtæ–‡ä»¶å¤„ç†ä¸­...'):
                st.write('è¯»å–txtæ–‡ä»¶ä¸­...')
                file_path = 'res/translation/eval_tgt.txt'
                if os.path.exists(file_path):
                    os.remove(file_path)
                stringio = StringIO(uploaded_eval_tgt_file.getvalue().decode("utf-8"))
                content = stringio.read()
                content = content.replace('\r\n', '\n')
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                st.session_state.transformer_eval_tgt_path = file_path
                st.write('txtæ–‡ä»¶å¤„ç†å®Œæˆâœ…')
            st.session_state.classification_eval_tgt_uploaded = False

        if st.session_state.transformer_training_src_path != '' and \
            st.session_state.transformer_training_tgt_path != '' and \
            st.session_state.transformer_eval_src_path != '' and \
            st.session_state.transformer_eval_tgt_path != '':
            with st.status('æ•°æ®é›†å¤„ç†ä¸­...'):
                st.write('æ•°æ®é›†å¤„ç†ä¸­...')
                st.session_state.controller.config_data_path('Transformer',
                                                             [st.session_state.transformer_training_src_path,
                                                              st.session_state.transformer_eval_src_path,
                                                              st.session_state.transformer_training_tgt_path,
                                                              st.session_state.transformer_eval_tgt_path])
                st.write('æ•°æ®é›†å¤„ç†å®Œæˆâœ…')
            st.write(f'æœ€å¤§å¥å­é•¿åº¦ä¸ºï¼š{st.session_state.controller.sentence_loader.max_sentence_len}\n'
                     f'å•è¯æ•°é‡ï¼š{len(st.session_state.controller.sentence_loader.tgt_word2vec.wv.key_to_index)}\n')

        with st.expander('æ–‡æœ¬æ•°æ®é›†å±•ç¤º'):
            st.write('è®­ç»ƒé›†-æºè¯­è¨€æ–‡æœ¬ï¼š')
            if st.session_state.transformer_training_src_path != '':
                count = 3
                content = ''
                for line in open(st.session_state.transformer_training_src_path, 'r', encoding='utf-8'):
                    if count > 0:
                        content += f'{line}'
                        count -= 1
                content += '......'
                st.code(content)
            else:
                st.write('> [è¯·ä¸Šä¼ è®­ç»ƒé›†-æºè¯­è¨€æ–‡æœ¬]')

            st.write('è®­ç»ƒé›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬ï¼š')
            if st.session_state.transformer_training_tgt_path != '':
                count = 3
                content = ''
                for line in open(st.session_state.transformer_training_tgt_path, 'r', encoding='utf-8'):
                    if count > 0:
                        content += f'{line}'
                        count -= 1
                content += '......'
                st.code(content)
            else:
                st.write('> [è¯·ä¸Šä¼ è®­ç»ƒé›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬]')

            st.write('æµ‹è¯•é›†-æºè¯­è¨€æ–‡æœ¬ï¼š')
            if st.session_state.transformer_eval_src_path != '':
                count = 3
                content = ''
                for line in open(st.session_state.transformer_eval_src_path, 'r', encoding='utf-8'):
                    if count > 0:
                        content += f'{line}'
                        count -= 1
                content += '......'
                st.code(content)
            else:
                st.write('> [è¯·ä¸Šä¼ æµ‹è¯•é›†-æºè¯­è¨€æ–‡æœ¬]')

            st.write('æµ‹è¯•é›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬ï¼š')
            if st.session_state.transformer_eval_tgt_path != '':
                count = 3
                content = ''
                for line in open(st.session_state.transformer_eval_tgt_path, 'r', encoding='utf-8'):
                    if count > 0:
                        content += f'{line}'
                        count -= 1
                content += '......'
                st.code(content)
            else:
                st.write('> [è¯·ä¸Šä¼ æµ‹è¯•é›†-ç›®æ ‡è¯­è¨€æ–‡æœ¬]')

    train = st.button('å¼€å§‹è®­ç»ƒï¼', type='primary')
    if train:
        with st.status('è®­ç»ƒå‰å‡†å¤‡...'):
            st.write('å‡†å¤‡è®­ç»ƒå™¨')
            st.session_state.controller.prepare_trainer()
            st.write('å‡†å¤‡è®­ç»ƒå™¨å®Œæˆâœ…')
        if st.session_state.controller.train():
            st.write('è®­ç»ƒå®Œæˆï¼âœ…')
            st.download_button('ä¸‹è½½æ¨¡å‹', data=pickle.dumps(st.session_state.model), file_name=f"trained_model.model")

        # optimizer = Adam(parameters=model.parameters(), beta=(0.9, 0.98), d_model=word_vector_size,
                         # warmup_step=400)

with prediction_tab:
    input_text = st.text_input('**è¾“å…¥è¦é¢„æµ‹çš„è¯­å¥**', placeholder="Type text...")
    predict_begin = st.button(':sparkles: :rainbow[å¼€å§‹é¢„æµ‹]', type='primary')
    if predict_begin:
        if st.session_state.controller.sentence_loader is None:
            st.error('è¯·å…ˆé…ç½®æ•°æ®é›†ï¼', icon="ğŸš¨")
        model = st.session_state.controller.model_config.get_model()
        if len(model.sub_models)  == 1 and type(model.sub_models['0']).__name__ == 'Transformer':
            with st.status('æ­£åœ¨é¢„æµ‹...'):
                out = predict(input_text, st.session_state.controller.sentence_loader, model.sub_models['0'])
                out = out.replace('[END]', '')
                st.write('é¢„æµ‹å®Œæˆâœ…')
            st.subheader("è¾“å‡ºç»“æœ")
            st.markdown(f'**{out}**')
        else:
            st.error('å·²é€‰æ¨¡å‹ä¸æ˜¯Transformerç±»å‹ï¼Œè¯·é‡æ–°é…ç½®æ¨¡å‹', icon="ğŸš¨")
